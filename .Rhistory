# Se selecciona mapa del pa?s para seleccionar puntos de interes ==========
#Se usan los l?mites del mapa para recortar la base de datos
mapa<-Boundaries
#Crear shapefile de puntos a partir de lonlat (corresponde a todas las estaciones virtuales, o sea, el rect?ngulo)
est_cuadro <- data.frame(lonlat)
est_cuadro$ID <- paste("id_", 1:nrow(est_cuadro), sep = "")
#est_cuadro <- SpatialPointsDataFrame(coords = lonlatDF[,1:2], proj4string = proj4string(mapa), bbox = lonlatDF)
coordinates(est_cuadro) <- ~ Var1 + Var2
proj4string(est_cuadro) <- proj4string(mapa)
#Se edita el archivo lonlat para seleccionar aquellos puntos que est?n dentro del l?mite pa?s
est_selec <- est_cuadro[mapa,] #perfecto, se guarda
#Se obtiene un archivo (dataframe) lonlat con los puntos seleccionados
est_selecDF <- data.frame(est_selec)
#Se crea un data frame que almacenar? en cada lista, los valores por d?a
DF_est <- data.frame(date = tpo2, prcp_chirps = NA)
#Se crea una lista cuyos nombres corresponde a lat long (que en el fondo son las estaciones)
lista_est <- list()
for (i in 1:nrow(est_selecDF)){ #Continuar desde ac?...
print(paste0("estacion ",i," de ",nrow(est_selecDF)))
lista_est[[i]] <- DF_est
names(lista_est)[i] <- as.character(est_selecDF[i,3])
}
#........................................
# Extraer valores desde el prcpc_array usando "est_selecDF"
# almacenar en la lista
l = 1
for (j in 1:dim(prcp_array)[3]){ #ac? no es array brick, OJO
print(paste0("mes ",j," de ",dim(prcp_array)[3]))
raster_uni <- prcp_array[,,j]
raster_uni <- raster(t(raster_uni), xmn = min(lon), xmx = max(lon), ymn = min(lat), ymx = max(lat))
raster_uni <- flip(raster_uni, "y")
for (k in 1:nrow(est_selecDF)){
valor_fecha <- extract(raster_uni, matrix(c(est_selecDF[k,1], est_selecDF[k,2]), ncol = 2))
lista_est[[k]][l,2] <- valor_fecha
}
l = 1+l
} # ac? finalizado debiera estar ordenados los valores por fecha.
#...........................................
# Exportar datos como txt
dir.create(paste0(getwd(),"/est_procesadas/"))
for (m in 1:length(lista_est)){
print(paste0("estacion ", m, "de ",length(lista_est)))
export <- lista_est[[m]]
write.table(export, paste0(getwd(),"/est_procesadas/", names(lista_est)[m], "_latam.txt"), sep =";", row.names = FALSE)
}
# Se exporta la metadata (Estaciones virtuales)
metaexp <- est_selecDF[,c(3,1,2)]
colnames(metaexp) <- c("station_id", "lon", "lat")
write.table(metaexp, paste0(getwd(),"/est_procesadas/","metadata.txt"), sep = ";", row.names = FALSE)
#.............................................................
#Convertir al formato CAZALAC BaseDatosEstaciones y BasedatosRegistros
EstacionesLong=list()
latam.list=list.files(path=paste0(getwd(),"/est_procesadas") ,
pattern = "\\latam.txt$")
latam.list=substr(latam.list, 1, nchar(latam.list)-10)
for (j in 1:length(latam.list)){
EstacionesLong[[j]]=read.table(paste0(getwd(),"/est_procesadas/",latam.list[j],"_latam.txt"),sep=";",header=TRUE)
}
BaseDatosRegistros=data.frame(id_station=rep(latam.list[1],36),
Year=1981:2016,
matrix(EstacionesLong[[1]][,2],ncol=12,byrow=T))
for (k in 2:length(latam.list)){
bd=data.frame(id_station=rep(latam.list[k],36),
Year=1981:2016,
matrix(EstacionesLong[[k]][,2],ncol=12,byrow=T))
BaseDatosRegistros=rbind(BaseDatosRegistros,bd)
}
colnames(BaseDatosRegistros)[3:14]=month.abb
# CORRECCION DE CEROS. TODOS LOS CEROS SON REEMPLAZADOS POR UN VALOR RANDOM UNIF ENTRE 0 Y 1
for (i in 3:14){
baseline.index = which(BaseDatosRegistros[,i] == 0)
noise = runif(length (  baseline.index ))
BaseDatosRegistros[baseline.index,i] = BaseDatosRegistros[baseline.index,i] + noise
}
#row.names(BaseRegistrosPr)=NULL
write.csv(BaseDatosRegistros,"BaseDatosRegistros.csv",sep=",",row.names=FALSE)
write.csv(BaseDatosRegistros,"BaseDarosRegistrosBackup.csv",sep=",",row.names=FALSE)
#BaseDatosEstaciones. Defino el tama?o total a 500
BaseDatosEstaciones=read.csv(paste0(getwd(),"/est_procesadas/metadata.txt"),sep=";",header=TRUE)
colnames(BaseDatosEstaciones)[1]="id_station"
row.names(BaseDatosEstaciones)=NULL
if (dim(BaseDatosEstaciones)[1]>500){
BaseDatosEstaciones=randomSample(BaseDatosEstaciones,500)
} else {
BaseDatosEstaciones=BaseDatosEstaciones
}
write.csv(BaseDatosEstaciones,"BaseDatosEstaciones.csv", row.names=FALSE)
write.csv(BaseDatosEstaciones,"BaseDatosEstacionesBackup.csv", row.names=FALSE)
#..........................................................END ...........................................
##################################################
## -------------------------------------------------
## Project: AfricanDroughtAtlas
## Script purpose:
## Date Created: 09-05-2023
## Baed on CRU: 02-08-2018
## Author 1: J. Nu침ez
## Author 2: H. Maureria
## Author 3: P. Rojas
## Email: hmaureria@cazalac.org
## -------------------------------------------------
## Notes:
##
##        -THIS TRY IS WITH REG ADAPT WITHOUT MODIFIERS
##################################################
#####
#import libraries
library(raster);library(rgdal);library(countrycode);library(rts);require(ncdf4);library(HelpersMG)
library(plyr);library(latticeExtra);library(reshape2);library(gdata);library(corrplot);library(sqldf)
library(zoo);library(Kendall);library(zyp);library(car);library(gtools);# Para mantener orden texto-numero en id_station
library(rgeos);library(lmom);library(lmomRFA);library(sp);library(rrcov);library(nsRFA);library(ModelMap)
library(maptools);library(stringr);library(raster);library(rasterVis);library(hydroGOF);library(randomForest);library(progress);#Check proper installation of SAG-GIS and RSAGA
library(RSAGA);library(gtools)
#####
#config
workdir = "C:/Users/pablo/OneDrive/Escritorio/CAZALAC/ADA/"
country="DJI" #PLEASE REPLACE WITH CORRESPONDING THREE ISO LETTER . IN THIS CASE BOTZWANA=BWA
#THREE LETTER CODES CAN BE FOUND IN "CountryISOCodes.csv"
#####
#Function
setwd(workdir)
source('DroughAtlasFunctions.R')
#####
#Check
rsaga.env()
rsaga.get.version()
setwd(paste0(workdir, country)) #changed slashes
getwd()
###################################################################################################################
#                                    BLOCK I.A. DATABASE CONSTRUCTION FROM CRU 3.21 or CHIRPS                     #
#                                    CHOOSE ONE OF THE TWO ALTERNATIVES BASED ON COUNTRY SIZE                     #
###################################################################################################################
##################################################################################################################
#                                         BLOCK II. VARIABLES AND INDICES  CALCULATION                           #
##################################################################################################################
Boundaries=readOGR(".",country) #Obtained from http://www.maplibrary.org/library/stacks/Africa/index.htm
projection(Boundaries)="+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0"
plot(Boundaries)
plot(Boundaries)
Boundaries
Boundaries=readOGR(".",country) #Obtained from http://www.maplibrary.org/library/stacks/Africa/index.htm
projection(Boundaries)="+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0"
plot(Boundaries)
Boundaries=readOGR(".",country) #Obtained from http://www.maplibrary.org/library/stacks/Africa/index.htm
projection(Boundaries)="+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0"
plot(Boundaries)
#BaseDatosEstaciones with 3 columns: factor, num, num
BaseDatosEstaciones <- read.csv("BaseDatosEstaciones.csv",sep=",")
head(BaseDatosEstaciones,3)
BaseDatosRegistros <- read.csv("BaseDatosRegistros.csv",sep=",")
head(BaseDatosRegistros,3)
#BaseDatosRegistros with 14 columns:factor, int, 12 num
BaseRegistrosPr=BaseDatosRegistros
# Monthly accumulated precipitation values
RegionDF<-BaseRegistrosPr
RegionDF[,1] <- factor(RegionDF[,1]) #Defino solamente los niveles del DF, ya que el subset mantiene todos los anteriores.
#SIMULACION
#RegionDF <- RegionDFSim
#RegionDF[,1] <- factor(RegionDF[,1])
#Almacenamiento de Estaciones pertenecientes a la region, en una lista
#(Paso Necesario, ya que se cambiara el formato a Long)
#---------------------------------------------------------------------
EstacionesWide <- list()
#levels(reorder(RegionDF[,1]))
for (i in mixedsort(levels(RegionDF[,1]))){
EstacionesWider <- subset(RegionDF, id_station == paste(i))
EstacionesWide[[i]] <- EstacionesWider
rm(EstacionesWider)
}
#Almacenamiento de Estaciones en formato Long y en formato necesario para c?lculo de H1
#--------------------------------------------------------------------------------------
EstacionesLong <- list()
#DatosH1 <- list()
for (j in 1:length(EstacionesWide)){
dfm <- EstacionesWide[[j]]
#De wide a long
# Conveertir data.frame de formato ancho a largo, se resta 1 para eliminar columna "Region"
dfm <- melt(dfm[,2:(ncol(dfm))], id.var="Year", variable_name="Month") #Dejar ANTES COMO YEAR #melt(dfm[,2:(ncol(dfm)-1)]
names(dfm) <- c("Year", "Month", "Lluvia")
# dfm$Mointh is factor, Convert to month number & calc yr_frac
lluvia_mo_num <- unclass(dfm$Month)
lluvia_mo_frac <- as.numeric(lluvia_mo_num/12 )
yr_frac <- dfm$Year + lluvia_mo_frac
# build consolidated data.frame
dfm <- data.frame(yr_frac, dfm)
dfm <- dfm[order(dfm$yr_frac), ]
#dfm <- dfm[!is.na(dfm$Lluvia),]
dfm <-dfm[2:4]
dfm[,2] <- as.character(dfm[,2])
EstacionesLong[[j]] <- dfm
#DatosH1[[j]] <- dfm[,3]
}
#Sumatoria de cada Estacion, que sera almacenado en otra lista
#---------------------------------------------------------
k <- 12 #This is a critical values because defines the time step to be analyzed latter
#Creacion de la lista donde se va a almacenar la suma.
EstacionesSuma <- list()
#Sumatorias, en base al valor de k, que se almacena en EstacionesSuma.
for (l in 1:length(EstacionesLong)){#Selecciono la Estacion en Long
datospp <- EstacionesLong[[l]][,3] #almaceno los valores de pp que seran sumados despues
EstacionSumar <- EstacionesLong[[l]] #se escoge la estacion en formato long
EstacionSumar[,3] <- NA #Se asigna columna de valores de pp como NA.
colnames(EstacionSumar)[3] <- names(EstacionesWide)[[l]]    #"Suma"
for (m in 1:nrow(EstacionSumar)){ #aca es donde se empieza a determinar si la sumatoria se hace o no.
FilaFinal <- m
FilaInicial <- (FilaFinal-(k-1))
if (FilaInicial<=0){
EstacionSumar[m,3]<-NA
} else{
EstacionSumar[m,3] <- sum(datospp[FilaInicial:FilaFinal])
}
}
EstacionesSuma[[l]] <- EstacionSumar #finalmente, se almacena la estacion sumada en una lista.
}
#Same names from "EstacionesWide" are assigned to "EstacionesSuma"
names(EstacionesSuma) <- names(EstacionesWide)
### JNunez request (bind BaseRegistrosPr w/ monthly sums) ---
BaseSums <- list()
for (u in 1:12){
BaseSums[[u]] <- sapply(EstacionesSuma, function(x) subset(x, Month == month.abb[u], select = colnames(x)[3]))
BaseSums[[u]] <- unlist(BaseSums[[u]])
names(BaseSums[[u]]) <- NULL
names(BaseSums)[u] <- paste(month.abb[u], "_", k, "_months", sep = "")
}
BaseRegistrosPr_sumas <- data.frame(matrix(unlist(BaseSums), nrow = nrow(BaseRegistrosPr), byrow=F))
colnames(BaseRegistrosPr_sumas) <- paste(month.abb, "_", k, sep = "")
## bind
BaseRegistrosPr <- cbind(BaseRegistrosPr, BaseRegistrosPr_sumas)
CumSum=data.frame(matrix(ncol = 12,nrow=dim(BaseRegistrosPr)[1]))
for (i in 1:dim(BaseRegistrosPr)[1]){
CumSum[i,1:12]=cumsum(as.numeric(BaseRegistrosPr[i,3:14]))
}
colnames(CumSum)=paste0("CumSum",month.abb)
BaseRegistrosPr=cbind(BaseRegistrosPr,CumSum)
write.csv(BaseRegistrosPr,"BaseRegistrosPr.csv",row.names=FALSE)
#.....................................................................................................................
#                   Calculation of several Indices like Julian Mean Day, Seasonality Index and Modified Fourier Index
JanDec=matrix(BaseRegistrosPr$CumSumDec)
DiaJulianoAng<-matrix(seq(15,345,30)*2*pi/365,nrow=length(BaseRegistrosPr[[1]]),ncol=12,byrow=TRUE)
Prec<-BaseRegistrosPr[match(month.abb,names(BaseRegistrosPr))]
x<-Prec*cos(DiaJulianoAng)/JanDec
y<-Prec*sin(DiaJulianoAng)/JanDec
xcos<-matrix(rowMeans(x),nrow=length(BaseRegistrosPr[[1]]),ncol=1)
ysin<-matrix(rowMeans(y),nrow=length(BaseRegistrosPr[[1]]),ncol=1)
xcossum<-matrix(rowSums(x),nrow=length(BaseRegistrosPr[[1]]),ncol=1)
ysinsum<-matrix(rowSums(y),nrow=length(BaseRegistrosPr[[1]]),ncol=1)
angulo<-atan(ysin/xcos)
angulo_corregido<-matrix(0,nrow=length(BaseRegistrosPr[[1]]),ncol=1)
for (k in 1:length(BaseRegistrosPr[[1]])) {
if (sum(is.na(xcos[k]>0))|sum(is.na(ysin[k]>0))) angulo_corregido[k]<-NA else
if (xcos[k]>0&ysin[k]>0)  angulo_corregido[k]<-angulo[k] else if (xcos[k]<0&ysin[k]<0) angulo_corregido[k]<-angulo[k]+pi  else if (ysin[k]>0&xcos[k]<0) angulo_corregido[k]<-angulo[k]+pi else   angulo_corregido[k]<-angulo[k]+2*pi
}
JMD<-(angulo_corregido*365)/(2*pi)
SI<-sqrt(xcossum^2+ysinsum^2)
IFM<-matrix(rowSums((Prec*Prec)/JanDec),nrow=length(BaseRegistrosPr[[1]]),ncol=1) # Esta linea realiza el calculo del Indice de Fourier Modificado
# C.5.3. Aggregate record indices and add to Stations's DataBase
BaseDatosIntermedia<-cbind(BaseRegistrosPr,SI,JMD,IFM)# Uno las columnas con los Indices calculados para cada registro. Contiene los valores anuales.
write.csv(BaseDatosIntermedia,"BaseIntermedia.csv")
#rm(BaseDatosIntermedia)
#BaseDatosIntermedia <- read.csv("BaseIntermedia.csv",sep=",")
BaseDatosIntermedia$id_station=as.factor(BaseDatosIntermedia$id_station) #se habilita esta parte. HMC
# C.5.4. Derivated variables
# C.5.4.1.  Mean Annual Precipitation
PMA_por_Estacion<-as.matrix(tapply(BaseDatosIntermedia$CumSumDec,BaseDatosIntermedia$id_station,mean,na.rm=TRUE))
# C.5.4.2. Seasonality Index (SI)
SI_por_Estacion<-as.matrix(tapply(BaseDatosIntermedia$SI,BaseDatosIntermedia$id_station,mean,na.rm=TRUE))
# C.5.4.3. JUlian Mean Day (JMD)
JMD_por_Estacion<-as.matrix(tapply(BaseDatosIntermedia$JMD,BaseDatosIntermedia$id_station,mean,na.rm=TRUE))
# C.5.4.4. Modified Fourier Index (IFM)
IFM_por_Estacion<-as.matrix(tapply(BaseDatosIntermedia$IFM,BaseDatosIntermedia$id_station,mean,na.rm=TRUE))
# C.5.4.5. Record Length (LongRec)
Longitud<-function(x) (length(x)-sum(is.na(x)))
LR_por_Estacion<-as.matrix(tapply(BaseDatosIntermedia$CumSumDec,BaseDatosIntermedia$id_station,Longitud))
# C.5.4.6. Firt year of record (FirstYear)
PrimerAnio_por_Estacion<-as.matrix(tapply(BaseDatosIntermedia$Year,BaseDatosIntermedia$id_station,min))
# C.5.4.7. Last year of record (LastYear)
UltimoAnio_por_Estacion<-as.matrix(tapply(BaseDatosIntermedia$Year,BaseDatosIntermedia$id_station,max))
# C.5.5. Add indices to Stations DataBase and remove objects from memory
id_station<-levels(BaseDatosIntermedia$id_station)
BaseDatosIndices<-data.frame(id_station=id_station,MAP=PMA_por_Estacion, SI_Medio=SI_por_Estacion,
JMD_Medio=JMD_por_Estacion, IFM_Medio=IFM_por_Estacion, RL_Station=LR_por_Estacion, FirstYear=PrimerAnio_por_Estacion,
LastYear=UltimoAnio_por_Estacion) #Ok, est치 arreglado habilitando la opci칩n de usar factores.
write.csv(BaseDatosIndices,"BaseDatosIndices.csv",row.names=FALSE)
#rm(BaseDatosIndices)
#BaseDatosIndices<-read.csv("BaseDatosIndices.csv",header=T,sep=",")
#Please check correct import. Dimensions and structure or both data.frames
#Please check that names under id_station are similar in both data.frames
BaseDatosEstaciones<-join(BaseDatosEstaciones,BaseDatosIndices,by="id_station") # Ac? uno las dos bases de datos a nivel de estaciones solamente, no de todos los registros. Contiene los valores medios
#Here an updated version of Stations DataBase is saved
write.csv(BaseDatosEstaciones,"BaseDatosEstaciones.csv",row.names=FALSE)
#remove(BaseDatosEstaciones)
#BaseDatosEstaciones<-read.csv("BaseDatosEstaciones.csv",header=T,sep=",")
head(BaseDatosEstaciones,5)
#...................................................................................................................
#                                     Trend, serial correlation, Mann-Kendall and Sen slope calculation
RegionTotalS<-sqldf(paste("SELECT id_station, Year, CumSumDec FROM BaseDatosEstaciones join BaseDatosIntermedia USING(id_station)",sep=""))
#RegionTotalS<-sqldf("select id_station, Year, JanDec from BaseCompleta where RL_Station>=15")
RegionTotalS_dat<-RegionTotalS[c("CumSumDec","Year")][,]
RegionTotalS_fac<-factor(RegionTotalS["id_station"][,])
RegTotalS<-split(RegionTotalS_dat,RegionTotalS_fac)#
estaciones<-length(RegTotalS)
#....................................................................................
for (est in 1:estaciones){
Y<-RegTotalS[[est]]$CumSumDec/mean(RegTotalS[[est]]$CumSumDec,na.rm=T)
X<-RegTotalS[[est]]$Year
XY<-cbind(X,Y)
orderX=order(X)
XY<-data.frame(XY[orderX,])
z <- read.zoo(XY)
gz <- zoo( x = NULL ,seq(min(time(z)), max(time(z))))
XYzoo<-merge(z, gz)
XYdf<-data.frame(X=index(XYzoo),Y=XYzoo,row.names=NULL)
mk<-as.numeric(MannKendall(as.ts(XYzoo)))[2]# Paquete Kendall
ss<-zyp.sen(Y~X,data=XYdf)[[1]][2] # Paquete zyp
fit=lm(Y~X,data=XYdf)
DW<-durbinWatsonTest(fit)#paquete car
lm.coeficients <- function (modelobject) {
if (class(modelobject) != "lm") stop("Not an object of class 'lm' ")
f <- summary(modelobject)$fstatistic
p <- pf(f[1],f[2],f[3],lower.tail=F)
s<-summary(modelobject)$coefficients[2]
attributes(s) <- NULL
attributes(p) <- NULL
salida<-list(slope=s,Pvalue=p)
return(salida)
}
RegTotalS[[est]]$Pendiente<-lm.coeficients(fit)$slope
RegTotalS[[est]]$Pvalue<-lm.coeficients(fit)$Pvalue
RegTotalS[[est]]$Autocorr<-DW[[1]]
RegTotalS[[est]]$DW_Pvalue<-DW[[3]]
RegTotalS[[est]]$Sen<-ss
RegTotalS[[est]]$MKPvalue<-mk
}
par(mfrow=c(1,2))
RegTotalS2<-ldply(RegTotalS, data.frame)
colnames(RegTotalS2)[1]<-'id_station'
Pendiente_por_Estacion<-as.matrix(tapply(RegTotalS2[[4]],RegTotalS2[[1]],mean))
hist(Pendiente_por_Estacion)
boxplot(Pendiente_por_Estacion)
Pvalue_por_Estacion<-as.matrix(tapply(RegTotalS2[[5]],RegTotalS2[[1]],mean))
hist(Pvalue_por_Estacion)
boxplot(Pvalue_por_Estacion)
Autocor_por_Estacion<-as.matrix(tapply(RegTotalS2[[6]],RegTotalS2[[1]],mean))
hist(Autocor_por_Estacion)
boxplot(Autocor_por_Estacion)
DW_por_Estacion<-as.matrix(tapply(RegTotalS2[[7]],RegTotalS2[[1]],mean))
hist(DW_por_Estacion)
boxplot(DW_por_Estacion)
Sen_por_Estacion<-as.matrix(tapply(RegTotalS2[[8]],RegTotalS2[[1]],mean))
hist(Sen_por_Estacion)
boxplot(Sen_por_Estacion)
MKPvalue_por_Estacion<-as.matrix(tapply(RegTotalS2[[9]],RegTotalS2[[1]],mean))
hist(MKPvalue_por_Estacion)
boxplot(MKPvalue_por_Estacion)
par(mfrow=c(1,1))
id_estaciones<-levels(as.factor(RegTotalS2[,1]))
BaseDatosTendenciaDW<-cbind(id_estaciones,Pendiente_por_Estacion,Pvalue_por_Estacion,Autocor_por_Estacion,
DW_por_Estacion,Sen_por_Estacion,MKPvalue_por_Estacion)
colnames(BaseDatosTendenciaDW)[c(1,2,3,4,5,6,7)]<-c('id_station','Pendiente','Pvalue','Autocorr','DW_Pvalue',
'Sen','MK')
#con esto nos evitamos tener que volver a cargar el df
write.csv(BaseDatosTendenciaDW, "BaseDatosTendenciaDW.csv", row.names=FALSE)
BaseDatosTendenciaDW = as.data.frame(BaseDatosTendenciaDW)
#rm(BaseDatosTendenciaDW) # Aca debo remover y volver a cargar la  Base de Datos en el sistema
#BaseDatosTendenciaDW <- read.csv("BaseDatosTendenciaDW.csv",sep=",",header=T)# Y vuelvo a cargar la Base de Datos
# Here an updated version of Stations DataBase is saved
BaseDatosEstaciones<-join(BaseDatosEstaciones,BaseDatosTendenciaDW,by="id_station") # Ac? uno las dos bases de datos a nivel de estaciones solamente.
write.csv(BaseDatosEstaciones,  "BaseDatosEstaciones.csv", row.names=FALSE)
#rm(BaseDatosEstaciones)
#BaseDatosEstaciones<-read.csv("BaseDatosEstaciones.csv",header=T, sep=",")
head(BaseDatosEstaciones,5) #Hasta el final del Block II, el script se ejecuta de forma normal, salvo peque침os ajustes.
#.................................................END OF BLOCK II..........................................................
# Ruta de los archivos netCDF
file1 <- paste0(getwd(),"/data1.nc")
file2 <- paste0(getwd(),"/data2.nc")
outputFile <-  paste0(getwd(),"/archivo_salida.nc")
# Just for one variable for now
dat_new <- cbind(
ncvar_get(file1, 'precipitation'),
ncvar_get(file2, 'precipitation'))
ncvar_get
require(ncdf4)
file1 <- paste0(getwd(),"/data1.nc")
file2 <- paste0(getwd(),"/data2.nc")
outputFile <-  paste0(getwd(),"/archivo_salida.nc")
# Just for one variable for now
dat_new <- cbind(
ncvar_get(file1, 'precipitation'),
ncvar_get(file2, 'precipitation'))
getwd()
workdir = "C:/Users/pablo/OneDrive/Escritorio/CAZALAC/ADA/"
country="ALLC" #PLEASE REPLACE WITH CORRESPONDING THREE ISO LETTER . IN THIS CASE BOTZWANA=BWA
# Setup, Country Code, Shape and raster creation ========
setwd(workdir)
# Listado de paises segun codigo ISO
if(!(country == "ALLC")){
ISO.codes=read.csv("CountryISOCodes.csv",sep=";")
Afr.country.list=as.character(ISO.codes$ThreeLetter)
Afr.country.name=countrycode(Afr.country.list, "iso3c","country.name")
COUTRYNUM = as.numeric(rownames(ISO.codes[ISO.codes$ThreeLetter == country,]))
# Seleccion del pais de trabajo
country=Afr.country.list[COUTRYNUM]
}
#Funcion para muestreo de estaciones cuando hay mas de 3500
randomSample = function(df,n) {
return (df[sample(nrow(df), n),])}
#Create working directory and set working directory
dir.create(paste0(workdir,country))
setwd(paste0(getwd(),"/",country))
# Ruta de los archivos netCDF
file1 <- paste0(getwd(),"/data1.nc")
file2 <- paste0(getwd(),"/data2.nc")
outputFile <-  paste0(getwd(),"/archivo_salida.nc")
# Just for one variable for now
dat_new <- cbind(
ncvar_get(file1, 'precipitation'),
ncvar_get(file2, 'precipitation'))
file1
paste0(getwd(),"/data1.nc")
paste0(getwd(),"/data2.nc")
file1
ncvar_get(file1, 'precipitation')
file1
ncvar_get(file1, 'precipitation')
#install.packages('ncdf4')
library(ncdf4)
library(raster)
var_names <- c('X', 'Y', 'T', 'precipitation')
var_names <- c('X', 'Y', 'T', 'precipitation')
for (var_name in var_names) {
# Create raster stack
x <- stack(
raster(file1, varname = var_name),
raster(file2, varname = var_name))
# Name each layer
names(x) <- c('01', '02')
writeRaster(x = x,
filename = paste0(var_name, '_out.nc'),
overwrite = TRUE,
format = 'CDF')
}
var_names <- c('precipitation')
for (var_name in var_names) {
# Create raster stack
x <- stack(
raster(file1, varname = var_name),
raster(file2, varname = var_name))
# Name each layer
names(x) <- c('01', '02')
writeRaster(x = x,
filename = paste0(var_name, '_out.nc'),
overwrite = TRUE,
format = 'CDF')
}
# libraries ========
library(raster)
library(countrycode)
library(rgdal)
library(ncdf4);library(chron);library(lattice);library(RColorBrewer)
library(rgdal);library(sp);library(raster)
# config ===========
workdir = "C:/Users/pablo/OneDrive/Escritorio/CAZALAC/ADA/"
country="ALLC" #PLEASE REPLACE WITH CORRESPONDING THREE ISO LETTER . IN THIS CASE BOTZWANA=BWA
# Setup, Country Code, Shape and raster creation ========
setwd(workdir)
# Listado de paises segun codigo ISO
if(!(country == "ALLC")){
ISO.codes=read.csv("CountryISOCodes.csv",sep=";")
Afr.country.list=as.character(ISO.codes$ThreeLetter)
Afr.country.name=countrycode(Afr.country.list, "iso3c","country.name")
COUTRYNUM = as.numeric(rownames(ISO.codes[ISO.codes$ThreeLetter == country,]))
# Seleccion del pais de trabajo
country=Afr.country.list[COUTRYNUM]
}
#Funcion para muestreo de estaciones cuando hay mas de 3500
randomSample = function(df,n) {
return (df[sample(nrow(df), n),])}
#Create working directory and set working directory
dir.create(paste0(workdir,country))
setwd(paste0(getwd(),"/",country))
#Define extent and margin. Deprecated. Not use.
if(!(country == "ALLC")){
Boundaries=raster::getData('GADM', country=country, level=1)
} else {
BoundariesAFR=readOGR("../AfricaDA.shp") #from http://www.maplibrary.org/library/stacks/Africa/index.htm
projection(BoundariesAFR)="+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0"
Boundaries = BoundariesAFR
}
writeOGR(Boundaries, dsn = '.', layer = country, driver = "ESRI Shapefile",overwrite_layer=TRUE)
#rm(Boundaries)
#save.image(paste0("C:/Users/jnune/Documents/AtlasSequiaALCCRU/",country,"/",country,".RData"))
##                CORREGIR MAPA MANUALMENTE
#.......................................................................
#Boundaries=readOGR(".",country)   #Obtenido de http://www.maplibrary.org/library/stacks/Africa/index.htm
plot(Boundaries)
Bound.Pol=extent(Boundaries)
if(Bound.Pol[1]>0) xmin=Bound.Pol[1]*0.95 else xmin=Bound.Pol[1]*1.05
if(Bound.Pol[2]>0) xmax=Bound.Pol[2]*1.05 else xmax=Bound.Pol[2]*0.95
if(Bound.Pol[3]>0) ymin=Bound.Pol[3]*0.95 else ymin=Bound.Pol[3]*1.05
if(Bound.Pol[4]>0) ymax=Bound.Pol[4]*1.05 else ymax=Bound.Pol[4]*0.95
xmin=round(xmin,4)
xmax=round(xmax,4)
ymin=round(ymin,4)
ymax=round(ymax,4)
print(url)
url=paste0('http://iridl.ldeo.columbia.edu/SOURCES/.UCSB/.CHIRPS/.v2p0/.monthly/.global/.precipitation/X/',xmin,'/',xmax,'/RANGEEDGES/Y/',ymin,'/',ymax,'/RANGEEDGES/T/(Jan%201981)/(Dec%202016)/RANGE/data.nc')
print(url)
install.packages("mergeNC")
library("mergeNC")
library(mergeNC)
library(ncdf.tools)
install.packages("ncdf.tools")
library(ncdf.tools)
